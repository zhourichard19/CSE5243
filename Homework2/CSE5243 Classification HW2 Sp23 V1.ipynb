{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# CSE 5243 - Introduction to Data Mining\n",
    "## Homework 2: Classification\n",
    "- Semester: Spring 2023\n",
    "- Instructor: Tom Bihari\n",
    "- Section Days/Time: Wednesday/Friday 9:35 AM or 12:45 PM (FILL IN)\n",
    "- Student Name: Richard Zhou\n",
    "- Student Email: zhou.3153@osu.edu\n",
    "- Student ID: 500387895\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: Overview"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Overview\n",
    "\n",
    "This assignment covers the **steps 4 and 5 of the six steps** of the **CRISP-DM process model** (Modelng and Evaluation). (See the CRISP-DM materials on CARMEN.)\n",
    "\n",
    "The **objectives** of this assignment are:\n",
    "- Solve a business problem by creating, evaluating, and comparing three classification models, and produce the outputs needed to provide business value for your stakeholders.\n",
    "- Experiment with built-in classification models in **scikit-learn**.\n",
    "\n",
    "### Dataset\n",
    "**NOTE: Since you already have pre-processed this dataset in the previous assignment, you may choose to use your \"cleaned up\" dataset from that assignment instead of re-doing the work here.**\n",
    "\n",
    "In this assignment, you will analyze an ALTERED copy of the “Hotel Booking Demand” dataset.\n",
    "- This dataset was pulled on 4/8/22 from: https://www.kaggle.com/datasets/jessemostipak/hotel-booking-demand\n",
    "- The dataset file is named: **hotel_bookings_with_errors_V1.csv**\n",
    "\n",
    "**The data has been altered slightly for use in course assignments,etc.:**\n",
    "- A unique ROW attribute has been added.\n",
    "- Errors have been added, such as: duplicated records, deleted records, deleted attribute values, erroneous attribute values.\n",
    "**DO NOT PUBLISH THIS DATASET - it contains intentionally wrong data!**\n",
    "\n",
    "### Problem Statement\n",
    "Assume that you are the Director of Data Science for Buckeye Resorts, Inc. (BRI), an international hotel chain.  As is the case for all hotel chains, reservation cancellations cause significant impacts to BRI, in profitability, logistics, and other areas.  Approximately **20%** of reservations are cancelled, and the cost to BRI of a cancelled reservation is **$500** on average. \n",
    "\n",
    "- BRI wants to improve (decrease) the cancellation rates at its hotels, using more tailored interventions, based on newly available detailed data.  BRI processes **100,000** reservations per year, so an incremental improvement in cancellation rates would have a significant impact.\n",
    "\n",
    "- One intervention being considered is to offer a special financial incentive to customers who have reservations, but who are “at risk” of cancellation.  BRI has performed a small pilot test, and has found that offering a **$80** discount to a customer who is planning to cancel is effective **35%** of the time in inducing the customer not to cancel (by locking in a “no cancellation” clause).\n",
    "\n",
    "- BRI leadership has asked your team to analyze the new data, and determine if it is suitable for developing analyses and models that would be effective in predicting which future reservations are likely to be at risk of cancellation, so the aforementioned financial incentive could be offered.\n",
    "\n",
    "- The head of BRI would then like you attend the upcoming BRI Board of Directors meeting.  She has asked you to present your findings to her and to the BOD, to help them decide whether to go forward with the planned tailored intervention approach, and/or to adjust or abandon the approach.  Your goal is to support the BOD in making a decision. \n",
    "\n",
    "**In the previous assignment**, you completed the sections for the first three steps of CRISP-DM.  You **explored** the dataset, and **prepared** a clean dataset from it that contains the kind of information you think might be useful.  You now will make use of the dataset.\n",
    "\n",
    "### Things To Do\n",
    "You now must **develop** and **evaluate** specific models for predicting the cancellations.  You will try the **off-the-shelf KNN classifier**, and **two other classifiers of your choice**.\n",
    "\n",
    "Some intial guidance / sugggestions:\n",
    "\n",
    "- You must develop a cost model from the problem statement above.  Consider creating a table that lists the benefit and cost dollar amounts for a decision on a **single customer**.  Note that the incentive will be \"offered\" if Predicted is True, and the incentive is \"needed\" if Actual is True:\n",
    "\n",
    "| Actual \"At Risk\" | Predicted \"At Risk\" | Incentive Benefit | Incentive Cost | Net Benefit (Benefit-Cost) |\n",
    "|---|---|---|---|---|\n",
    "| False | False | 0 | 0 | 0 |\n",
    "| False | True  | 0 | 80 | -80 |\n",
    "| True  | False | 0 | 0 | 0 |\n",
    "| True  | True  | 175 | 80 | 95 |\n",
    "\n",
    "- Much of the code below may be repetitive.  Consider creating a few reusable functions that can be called for each of the models you build (e.g., evaluation functions).\n",
    "\n",
    "- **Follow the instructions** in each of the sections below.\n",
    "\n",
    "It is essential that you **communicate** your goals, thought process, actions, results, and conclusions to the **audience** that will consume this work.  It is **not enough** to show just the code.  It is not appropriate to show long sections of **unexplained printout**, etc.  Be kind to your readers and provide value to them!\n",
    "\n",
    "**ALWAYS follow this pattern** when doing **each portion** of the work.  This allows us to give feedback and assign scores, and to give partial credit.  Make it easy for the reader to understand your work.\n",
    "- Say (briefly) **what** you are trying to do, and **why**.\n",
    "- Do it (code).\n",
    "- Show or describe the **result** clearly (and briefly as needed), and explain the significant **conclusions or insights** derived from the results. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Collaboration\n",
    "For this assignment, you should work as an individual. You may informally discuss ideas with classmates, but your work should be your own.\n",
    "\n",
    "### What you need to turn in:\n",
    "1)\tCode\n",
    "\n",
    "-\tFor this homework, the code is the Jupyter Notebook.  Use the provided Jupyter Notebook template, and fill in the appropriate information.\n",
    "-\tYou may use common Python libraries for I/O, data manipulation, data visualization, etc. (e.g., NumPy, Pandas, MatPlotLib,…) \n",
    "-\tYou may not use library operations that perform, in effect, the “core” computations for this homework (e.g., If the assignment is to write a K-Means algorithm, you may not use a library operation that, in effect, does the core work needed to implement a K-Means algorithm.).  When in doubt, ask the grader or instructor.  (**Note: For this assignment, you *will* be using build in library functions, so you are permitted to do so.  You may not, however, make use of a single function that does *all* of the work for you.**\n",
    "-\tThe code must be written by you, and any significant code snips you found on the Internet and used to understand how to do your coding for the core functionality must be attributed.  (You do not need to attribute basic functionality – matrix operations, IO, etc.)\n",
    "-\tThe code must be commented sufficiently to allow a reader to understand the algorithm without reading the actual Python, step by step.\n",
    "-\t**When in doubt, ask the grader or instructor.**\n",
    "\n",
    "2)\tWritten Report\n",
    "-\tFor this homework, the report is the Jupyter Notebook.  The report should be well-written.  Please proof-read and remove spelling and grammar errors and typos.\n",
    "-\tThe report should discuss your analysis and observations. Key points and findings must be written in a style suitable for consumption by non-experts.  Present charts and graphs to support your observations. If you performed any data processing, cleaning, etc., please discuss it within the report.\n",
    "\n",
    "### Grading\n",
    "\n",
    "1.\tOverall readability and organization of your report (5%)\n",
    "> - Is it well organized and does the presentation flow in a logical manner?\n",
    "> - Are there no grammar and spelling mistakes?\n",
    "> - Do the charts/graphs relate to the text?\n",
    "> - Are the summarized key points and findings understandable by non-experts?\n",
    "> - Do the Overview and Conclusions provide context for the entire exercise?\n",
    "2.\tEvaluation Method (10%)\n",
    "> - Does your evaluation method meet the needs of the developer (you) as well as the needs of your business stakeholders?\n",
    "> - Is the evaluation method sound?\n",
    "> - Did you describe both the method itself and why you chose it?\n",
    "3.\tPre-Processing of the Dataset (10%)\n",
    "> - Did you make reasonable choices for pre-processing, and explain why you made them?\n",
    "4.\tEvaluation of the KNN Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "5.\tEvaluation of the Second Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "6.\tEvaluation of the Third Classifier (20%)\n",
    "> - Is your algorithm design and coding correct?\n",
    "> - Is it well documented?\n",
    "> - Have you made an effort to tune it for good performance?\n",
    "> - Is the evaluation sound?\n",
    "7.\tComparison of the Three Classifiers (10%)\n",
    "> - Is the comparison sound?\n",
    "> - Did you choose a specific classifier as best and explain why?\n",
    "8.  Conclusions (5%)\n",
    "> - Did you summarize appropriately your critical findings. \n",
    "> - Did you provide appropriate conclusions and next steps.\n",
    "\n",
    "### How to turn in your work on Carmen:\n",
    "\n",
    "Submit to Carmen the Jupyter Notebook. You do not need to include the input data.\n",
    "\n",
    "**HAVE FUN!**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "# Section: Overview\n",
    "- Insert a short description of the scope of this exercise, any supporting information, etc.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am creating classifications to evaluate the data in 3 different ways. This will help me pitch my conclusion to the company and support what I feel would be most beneficial to the company."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: Setup\n",
    "- Add any needed imports, helper functions, etc., here.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 1 - Evaluation Method\n",
    "- Define measures for evaluating the classification models you develop.  Explain why the measures you choose provide a useful view into the value and usefulness of the model you eventually chose for the company to use.  **Note: In this section, you should define and explain your measures.  You may create a reusable function here if you like.  You then will use the functions in later sections.**\n",
    "- Define two types:\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 1.1 - Define measures that **do not** include the cost information\n",
    "- (e.g., confusion matrices, accuracy, precision, recall, F-measures, etc.).\n",
    "- Consider using: from sklearn.metrics import classification_report, confusion_matrix\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#!pip install matplotlib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#matplotlib.use('Qt5Agg')\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "pd.set_option('display.max_columns', 50) #include to avoid ... in middle of display\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I implement most of my method calls for the jupyter notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "## Section: 1.2 - Define measures that **do** include the cost information\n",
    "- (e.g., using cost matrices).\n",
    "- Consider creating a function that takes a confusion matrix and calculates the cost.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here is an old example, with five possible values:\n",
    "def calculate_cost(conf_matrix):\n",
    "# Fill in the cost matrix values\n",
    "#                           PREDICTED VALUES\n",
    "#                      0     1     \n",
    "    cost_matrix = [[0, -80],   # 0\n",
    "                   [0, 95]]   # 1\n",
    "    total = 0\n",
    "    for r in range(0, 2):\n",
    "        for c in range(0, 2):\n",
    "            total = total + cost_matrix[r][c] * conf_matrix[r][c]\n",
    "    return total"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This calculates the cost from the cost matrix above and also will be used in each of the classifier algorithms in order to calculate how much money the implementation is expected to cost."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 2 - Pre-Processing of the Dataset\n",
    "- Load the dataset.\n",
    "- Split the dataset into a Training dataset and a Test dataset based on the class attribute.  Keep them separate and use the Training dataset for training/tuning and the Test dataset for testing. For consistency, use the **train_test_split** operation available in SciKit Learn (use a specific random seed, so it is reproducible).\n",
    "  - from sklearn.model_selection import train_test_split\n",
    "  - X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "- **NOTE: You have done much of the data preprocessing in the previous assignment, so you don't have to re-do it here.  You can either copy the necessary code from the previous assignment, or generate the clean dataset from the previous assignment and load it here.**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.1 - Explore the attributes\n",
    "- As in Homework 1, explore the attributes briefly. Reference the website listed in the Introduction.\n",
    "- Provide basic statistics for the attributes.\n",
    "- List which attributes are Nominal (even though they are encoded as numbers), Ordinal, Interval, Ratio.\n",
    "- **NOTE: Just summarize here.  You will need to know which attributes are Nominal, etc., so it would be useful to list them here.**\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I am decalring what all of the nominal, ordinal, interval, and ratio attributes are and also assigning them to a specfic list accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "nominal_attribute_names = ['hotel', 'arrival_date_month', 'meal', 'country', 'market_segment', 'distribution_channel', 'reserved_room_type', 'assigned_room_type', 'deposit_type', 'agent', 'company', 'customer_type', 'required_car_parking_spaces', 'total_of_special_requests', 'reservation_status', 'reservation_status_date']\n",
    "ordinal_attribute_names = []\n",
    "interval_attribute_names = ['lead_time', 'arrival_date_year', 'arrival_date_week_number', 'arrival_date_day_of_month', 'is_repeated_guest', 'previous_cancellations', 'previous_bookings_not_canceled']\n",
    "ratio_attribute_names = ['adults', 'children', 'babies', 'booking_changes', 'days_in_waiting_list']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The statistics in the tables are that the most impactful partss are the is_repeated_guest, previous_cancellations, and previous_bookings_not_cancelled. This is because those mark a history of what could also lead to who can and might cancel. On top of that, correlation is largest in previoius_bookings_not_cancelled and the p-value is lowest in previous cancelations. Also in the website which is kaggle contains the data and some graphs to show how the data is represented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.2 - Revise the dataset\n",
    "- Review the meanings of the attributes and consider removing redundant or (likely) irrelevant attributes, combining attributes, etc., to reduce the number of attributes.\n",
    "- (You may choose to use techniques such as those you used in Homework 1 to analyze the impacts of individual attributes on the CLASS attribute.)\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "-**NOTE: You can just load your cleaned-up dataset here if you like.**\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping unwatned variables with low correlations and also do not effect the data set as noted from homework 1. On top of that, creating dummy values for catergorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ROW</th>\n",
       "      <th>is_canceled</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>arrival_date_year</th>\n",
       "      <th>arrival_date_week_number</th>\n",
       "      <th>arrival_date_day_of_month</th>\n",
       "      <th>adults</th>\n",
       "      <th>children</th>\n",
       "      <th>babies</th>\n",
       "      <th>is_repeated_guest</th>\n",
       "      <th>previous_cancellations</th>\n",
       "      <th>previous_bookings_not_canceled</th>\n",
       "      <th>booking_changes</th>\n",
       "      <th>days_in_waiting_list</th>\n",
       "      <th>adr</th>\n",
       "      <th>required_car_parking_spaces</th>\n",
       "      <th>total_of_special_requests</th>\n",
       "      <th>Resort Hotel</th>\n",
       "      <th>August</th>\n",
       "      <th>December</th>\n",
       "      <th>February</th>\n",
       "      <th>January</th>\n",
       "      <th>July</th>\n",
       "      <th>June</th>\n",
       "      <th>March</th>\n",
       "      <th>May</th>\n",
       "      <th>November</th>\n",
       "      <th>October</th>\n",
       "      <th>September</th>\n",
       "      <th>Complementary</th>\n",
       "      <th>Corporate</th>\n",
       "      <th>Direct</th>\n",
       "      <th>Groups</th>\n",
       "      <th>Offline TA/TO</th>\n",
       "      <th>Onlin TA</th>\n",
       "      <th>Online TA</th>\n",
       "      <th>Undefined</th>\n",
       "      <th>Direct</th>\n",
       "      <th>GDS</th>\n",
       "      <th>TA/TO</th>\n",
       "      <th>Undefined</th>\n",
       "      <th>Group</th>\n",
       "      <th>Transient</th>\n",
       "      <th>Transient-Party</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>342</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>737</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "      <td>2015</td>\n",
       "      <td>27</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>9995</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>9996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>31</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>9997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>9998</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>9999</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ROW  is_canceled  lead_time  arrival_date_year  \\\n",
       "0         0          0.0        342               2015   \n",
       "1         1          0.0        737               2015   \n",
       "2         2          0.0          7               2015   \n",
       "3         3          0.0         13               2015   \n",
       "4         4          0.0         14               2015   \n",
       "...     ...          ...        ...                ...   \n",
       "9996   9995          1.0         28               2017   \n",
       "9997   9996          1.0         31               2017   \n",
       "9998   9997          1.0          0               2017   \n",
       "9999   9998          1.0          1               2017   \n",
       "10000  9999          1.0          1               2017   \n",
       "\n",
       "       arrival_date_week_number  arrival_date_day_of_month  adults  children  \\\n",
       "0                            27                          1       2       0.0   \n",
       "1                            27                          1       2       0.0   \n",
       "2                            27                          1       1       0.0   \n",
       "3                            27                          1       1       0.0   \n",
       "4                            27                          1       2       0.0   \n",
       "...                         ...                        ...     ...       ...   \n",
       "9996                          5                          3       2       0.0   \n",
       "9997                          5                          3       1       0.0   \n",
       "9998                          5                          4       2       0.0   \n",
       "9999                          5                          4       2       0.0   \n",
       "10000                         5                          4       2       0.0   \n",
       "\n",
       "       babies  is_repeated_guest  previous_cancellations  \\\n",
       "0           0                  0                       0   \n",
       "1           0                  0                       0   \n",
       "2           0                  0                       0   \n",
       "3           0                  0                       0   \n",
       "4           0                  0                       0   \n",
       "...       ...                ...                     ...   \n",
       "9996        0                  0                       0   \n",
       "9997        0                  0                       0   \n",
       "9998        0                  0                       0   \n",
       "9999        0                  0                       0   \n",
       "10000       0                  0                       0   \n",
       "\n",
       "       previous_bookings_not_canceled  booking_changes  days_in_waiting_list  \\\n",
       "0                                   0                3                     0   \n",
       "1                                   0                4                     0   \n",
       "2                                   0                0                     0   \n",
       "3                                   0                0                     0   \n",
       "4                                   0                0                     0   \n",
       "...                               ...              ...                   ...   \n",
       "9996                                0                0                     0   \n",
       "9997                                0                0                     0   \n",
       "9998                                0                0                     0   \n",
       "9999                                0                0                     0   \n",
       "10000                               0                0                     0   \n",
       "\n",
       "        adr  required_car_parking_spaces  total_of_special_requests  \\\n",
       "0       0.0                            0                          0   \n",
       "1       0.0                            0                          0   \n",
       "2      75.0                            0                          0   \n",
       "3      75.0                            0                          0   \n",
       "4      98.0                            0                          1   \n",
       "...     ...                          ...                        ...   \n",
       "9996   48.0                            0                          0   \n",
       "9997   58.0                            0                          0   \n",
       "9998   48.0                            0                          2   \n",
       "9999   68.0                            0                          1   \n",
       "10000  48.0                            0                          0   \n",
       "\n",
       "       Resort Hotel  August  December  February  January  July  June  March  \\\n",
       "0                 1       0         0         0        0     1     0      0   \n",
       "1                 1       0         0         0        0     1     0      0   \n",
       "2                 1       0         0         0        0     1     0      0   \n",
       "3                 1       0         0         0        0     1     0      0   \n",
       "4                 1       0         0         0        0     1     0      0   \n",
       "...             ...     ...       ...       ...      ...   ...   ...    ...   \n",
       "9996              1       0         0         1        0     0     0      0   \n",
       "9997              1       0         0         1        0     0     0      0   \n",
       "9998              1       0         0         1        0     0     0      0   \n",
       "9999              1       0         0         1        0     0     0      0   \n",
       "10000             1       0         0         1        0     0     0      0   \n",
       "\n",
       "       May  November  October  September  Complementary  Corporate  Direct  \\\n",
       "0        0         0        0          0              0          0       1   \n",
       "1        0         0        0          0              0          0       1   \n",
       "2        0         0        0          0              0          0       1   \n",
       "3        0         0        0          0              0          1       0   \n",
       "4        0         0        0          0              0          0       0   \n",
       "...    ...       ...      ...        ...            ...        ...     ...   \n",
       "9996     0         0        0          0              0          0       0   \n",
       "9997     0         0        0          0              0          0       0   \n",
       "9998     0         0        0          0              0          0       1   \n",
       "9999     0         0        0          0              0          0       0   \n",
       "10000    0         0        0          0              0          0       0   \n",
       "\n",
       "       Groups  Offline TA/TO  Onlin TA  Online TA  Undefined  Direct  GDS  \\\n",
       "0           0              0         0          0          0       1    0   \n",
       "1           0              0         0          0          0       1    0   \n",
       "2           0              0         0          0          0       1    0   \n",
       "3           0              0         0          0          0       0    0   \n",
       "4           0              0         0          1          0       0    0   \n",
       "...       ...            ...       ...        ...        ...     ...  ...   \n",
       "9996        0              0         0          1          0       0    0   \n",
       "9997        0              0         0          1          0       0    0   \n",
       "9998        0              0         0          0          0       1    0   \n",
       "9999        0              0         0          1          0       0    0   \n",
       "10000       0              0         0          1          0       0    0   \n",
       "\n",
       "       TA/TO  Undefined  Group  Transient  Transient-Party  \n",
       "0          0          0      0          1                0  \n",
       "1          0          0      0          1                0  \n",
       "2          0          0      0          1                0  \n",
       "3          0          0      0          1                0  \n",
       "4          1          0      0          1                0  \n",
       "...      ...        ...    ...        ...              ...  \n",
       "9996       1          0      0          1                0  \n",
       "9997       1          0      0          1                0  \n",
       "9998       0          0      0          1                0  \n",
       "9999       1          0      0          1                0  \n",
       "10000      1          0      0          1                0  \n",
       "\n",
       "[10000 rows x 44 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"..\\Homework1\\hotel_bookings_with_errors_V1.csv\")\n",
    "clean_data_df = data_df.copy()\n",
    "clean_data_df['company'] = clean_data_df['company'].replace(to_replace='Onlin TA', value='Online TA')\n",
    "clean_data_df['is_canceled'] = clean_data_df['is_canceled'].fillna(0)\n",
    "clean_data_df['children'].fillna(0, inplace=True)\n",
    "clean_data_df.drop(5,inplace=True)\n",
    "data = clean_data_df.drop(['meal','country','company', 'agent', 'reserved_room_type','assigned_room_type','deposit_type','stays_in_weekend_nights',\n",
    "       'stays_in_week_nights','reservation_status','reservation_status_date'], axis=1)\n",
    "\n",
    "data = pd.concat([data, \n",
    "                 pd.get_dummies(data['hotel'], drop_first=True), \n",
    "                 pd.get_dummies(data['arrival_date_month'], drop_first=True), \n",
    "                 pd.get_dummies(data['market_segment'], drop_first=True),\n",
    "                 pd.get_dummies(data['distribution_channel'], drop_first=True),\n",
    "                 pd.get_dummies(data['customer_type'], drop_first=True)\n",
    "                 ], axis=1)\n",
    "\n",
    "data = data.drop(['hotel','arrival_date_month','market_segment','distribution_channel','customer_type'], axis=1)\n",
    "\n",
    "data.head(10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 2.3 - Transform the attributes\n",
    "- Consider transforming the remaining attributes (e.g., using the data dictionary to replace the numbers with text values for some attributes – this might or might not be useful), normalizing / scaling values, encoding labels (if necessary), etc.\n",
    "- Describe what you chose to do (and not do), and why.\n",
    "-**NOTE: If you want to do any additional transformations, you can do them here.**\n",
    "  - You also may need to do some specific transformations below for each of the classification models you choose.\n",
    "-**IMPORTANT: Any transformations you do to the datasets (particularly the Test dataset) must not artificially impact the evaluation measures.  We want the chosen classification model to work \"in the real world\", and the Test dataset is an approximation of the real world.**\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will not be doing any transformations because I do not think it is needed for my evaluation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 3 - Evaluation of the Off-The-Shelf KNN Classifier\n",
    "- Select the KNN classifier from the SciKit Learn library and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.1 - Configure the off-the-shelf KNN classifier\n",
    "- Use the KNeighborsClassifier from the SciKit Learn library\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I first imported the classifier needd for KNN and also imported the confusion_matrix and roc_curve. The point of getting the confusion matrix is because it is needed in order to analyze how well that my classifier ran and in order to analyze the accuracy, and recall. On top of the that the roc curve allows for us to pit our True positive against our false positive in order to get another accuracy rate with only those two values. I instantiate the learningg model to have 1 cluster because in cell 25 it is seen that that is the most optimal amount. Next I fit the model so it is the right sizer and test the model to predict the model to see what it will predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_curve, auc\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y = data['is_canceled']\n",
    "X = data.drop('is_canceled', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state = 1000)\n",
    "\n",
    "# Instantiate learning model (k = 3)\n",
    "knn_clf = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "# Fitting the model\n",
    "knn_clf.fit(X_train, y_train.squeeze())\n",
    "\n",
    "# Predicting the Test set results\n",
    "knn_y_pred = knn_clf.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prediction array that my model did"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the length of the model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35817,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_y_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.2 - Run and evaluate the classifier\n",
    "- Try several values of the K parameter and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation methods you defined above.\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I run the confusion matrix for my model and as you can see I have a true positive of 21984, True negative of 12406, False positive of 787, and false negative of 640. This confusion matrix will allow for me to do some more analysis on the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21984,   640],\n",
       "       [  787, 12406]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_cm = confusion_matrix(y_test, knn_y_pred)\n",
    "knn_cm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I calculate the accuracy of our model to see how much it got right when comparing all of the values in the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of our model is equal 96.02 %.\n"
     ]
    }
   ],
   "source": [
    "knn_accuracy = accuracy_score(y_test, knn_y_pred)*100\n",
    "print('Accuracy of our model is equal ' + str(round(knn_accuracy, 2)) + ' %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here when plotting an ROC Curve, we see that that True positive against the false positive still has a 96 percent accuracy which is good because that means the model can accurately discerne true positive and false positive values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_scores = knn_clf.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_scores[:, 1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.title('ROC Curve of kNN')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running multiple K parameters we can see that the less parameters we have the better, with 1 paramter we get an accuracy of 96.14, 2 paramaters is 96.13, and 3 parameters is 95.22. We can also see the most optimal amount of parameters from the graph cell 106. The performance of the classifier is extremeley accurate which is good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating list of K for KNN \n",
    "# What if you want to do Leave-One-Out Cross Validation\n",
    "\n",
    "#k_list = list(range(1,50,1))\n",
    "## creating list of cv scores\n",
    "#knn_cv_scores = []\n",
    "\n",
    "#for k in k_list:\n",
    "#    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "#    knn_scores = cross_val_score(knn, X_train, y_train.squeeze(), cv=10, scoring='accuracy')\n",
    "#    knn_cv_scores.append(knn_scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeled from: https://www.kaggle.com/skalskip/iris-data-visualization-and-knn-classification\n",
    "\n",
    "#def optimal_knn_value (k_list, knn_cv_scores):\n",
    "\n",
    "#    plt.figure()\n",
    "#    plt.figure(figsize=(15,10))\n",
    "#    plt.title('The optimal number of neighbors', fontsize=20, fontweight='bold')\n",
    "#    plt.xlabel('Number of Neighbors K', fontsize=15)\n",
    "#    plt.ylabel('Accuracy', fontsize=15)\n",
    "#    sns.set_style(\"whitegrid\")\n",
    "#    plt.plot(k_list, knn_cv_scores)\n",
    "#    plt.show()\n",
    "    \n",
    "#optimal_knn_value(k_list, knn_cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate learning model (k = 3)\n",
    "#knn_final_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fitting the model\n",
    "#knn_final_classifier.fit(X_train, y_train.squeeze())\n",
    "\n",
    "# Predicting the Test set results\n",
    "#knn_final_y_pred = knn_final_classifier.predict(X_test)\n",
    "\n",
    "#knn_final_cm = confusion_matrix(y_test, knn_final_y_pred)\n",
    "#print(knn_final_cm)\n",
    "#knn_final_accuracy = accuracy_score(y_test, knn_final_y_pred)*100\n",
    "#print('Accuracy of our model is equal ' + str(round(knn_final_accuracy, 2)) + ' %.')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where I calculate the cost that it takes to implement the KNN classifier in amount of money. The cost is $1,127,370 in order to implement this approach but this approach does give the hgihest accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1127370"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cost(knn_cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 3.3 - Evaluate the choice of the KNN classifier\n",
    "- What characteristics of the problem and data made KNN a good or bad choice?\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The characteristc of the problem and data that made KNN a good choice because there is no spontanity and there are clear differences. The reasons for why people cancel or do not cancel overlap and can easily be compared when one neighborhood has one pattern while the other one has a drastically different pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 4 - Evaluation of Off-The-Shelf Classifier #2\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data['is_canceled']\n",
    "X = data.drop('is_canceled', axis = 1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3,random_state = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation methods you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#Create a Gaussian Classifier\n",
    "rf_clf=RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "#Train the model using the training sets y_pred=clf.predict(X_test)\n",
    "rf_clf.fit(X_train,y_train.squeeze())\n",
    "\n",
    "rf_y_pred=rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[22281   343]\n",
      " [  514 12679]]\n",
      "Accuracy of our model is equal 97.61 %.\n"
     ]
    }
   ],
   "source": [
    "rf_cm = confusion_matrix(y_test, rf_y_pred)\n",
    "print(rf_cm)\n",
    "rf_accuracy = accuracy_score(y_test, rf_y_pred)*100\n",
    "print('Accuracy of our model is equal ' + str(round(rf_accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1177065"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cost(rf_cm)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ROC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 4.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The random forest uses many single decision trees to make the judgement. This is extremely usefull with uncorrelated models because it uses randomness of features when building each individual tree. This is extrememly useful with the dataset that we have now because, there are only a couple main attribtues that factor the final decision but there are also trends that lie in many attributes like the adults or the time of month that the guests are coming in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 5 - Evaluation of Off-The-Shelf Classifier #3\n",
    "- As with the KNN classifier above, choose another classifier from the SciKit Learn library (Decision Tree, SVM, Logistic Regression, etc.) and run it on the dataset.\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.1 - Configure the classifier\n",
    "- Use the appropriate classifier from the SciKit Learn library.\n",
    "- Explain all setup, parameters and execution options you chose to set, and why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# instantiate the model (using the default parameters)\n",
    "logreg = LogisticRegression(random_state=16)\n",
    "\n",
    "# fit the model with data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = logreg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.2 - Run and evaluate the classifier\n",
    "- Try several values of the parameters (if appropriate) and compare the results.\n",
    "- Evaluate the performance of the classifier, using the evaluation methods you defined above.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[18906  3718]\n",
      " [ 7908  5285]]\n",
      "Accuracy of our model is equal 67.54 %.\n"
     ]
    }
   ],
   "source": [
    "logreg = confusion_matrix(y_test, y_pred)\n",
    "print(logreg)\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)*100\n",
    "print('Accuracy of our model is equal ' + str(round(rf_accuracy, 2)) + ' %.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "204635"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_cost(logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 5.3 - Evaluate the choice of the classifier\n",
    "- What characteristics of the problem and data made the classifier a good or bad choice?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 6 - Comparison of the Three Classifiers\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.1 - Compare the performance of these classifiers to each other\n",
    "- What are their strong and weak points?\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Section: 6.2 - Choose a Best Classifier\n",
    "- Choose one of the three classifiers as best and explain why.\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# Section: 7 - Conclusions\n",
    "- Write a paragraph on what you discovered or learned from this homework.\n",
    "- What are your overall conclusions about the data?\n",
    "- What did you learn? What would you explore further with additional data, time or resources. What might \"future research\" require to gain deeper insight? \n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "### END-OF-SUBMISSION\n",
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "vscode": {
   "interpreter": {
    "hash": "932ebfec5d48865397cfdef02b45503e0ff9541558567f53ec81f672f84eaf9c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
